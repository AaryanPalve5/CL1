{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assignment ML2: Uber Fare Prediction (Linear, Ridge, Lasso)\n",
    "# Educational version: clear comments and printed outputs.\n",
    "# NOTE: Replace './uber.csv' with your dataset path if different.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset (user should provide file)\n",
    "path = \"./uber.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Loaded dataset:\", path)\n",
    "except Exception as e:\n",
    "    print(\"Could not load './uber.csv' â€” generating synthetic sample dataset instead. Replace with your file for real results.\\nError:\", e)\n",
    "    np.random.seed(42)\n",
    "    n = 1000\n",
    "    df = pd.DataFrame({\n",
    "        \"pickup_latitude\": np.random.uniform(40.5, 41.0, n),\n",
    "        \"pickup_longitude\": np.random.uniform(-74.3, -73.7, n),\n",
    "        \"dropoff_latitude\": np.random.uniform(40.5, 41.0, n),\n",
    "        \"dropoff_longitude\": np.random.uniform(-74.3, -73.7, n),\n",
    "        \"passenger_count\": np.random.randint(1, 5, n),\n",
    "        \"distance_km\": np.random.exponential(2, n),\n",
    "    })\n",
    "    # synthetic fare (target)\n",
    "    df[\"fare_amount\"] = 2.5 + 1.2 * df[\"distance_km\"] + 0.5 * df[\"passenger_count\"] + np.random.normal(0, 2, n)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# Basic preprocessing\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[\"fare_amount\"])\n",
    "# Identify numeric and categorical columns automatically\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != \"fare_amount\"]\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "print(\"\\nNumeric cols:\", numeric_cols)\n",
    "print(\"Categorical cols:\", categorical_cols)\n",
    "\n",
    "# Outlier detection using IQR for target\n",
    "Q1 = df[\"fare_amount\"].quantile(0.25)\n",
    "Q3 = df[\"fare_amount\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "outliers = df[(df[\"fare_amount\"] < lower) | (df[\"fare_amount\"] > upper)]\n",
    "print(f\"\\nDetected {len(outliers)} outliers in fare_amount (using IQR).\")\n",
    "# For demonstration, we won't drop them automatically; show distribution\n",
    "plt.figure(figsize=(6,3))\n",
    "sns.boxplot(x=df[\"fare_amount\"])\n",
    "plt.title(\"Fare Amount Boxplot\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation (numeric features)\n",
    "if numeric_cols:\n",
    "    corr = df[numeric_cols + [\"fare_amount\"]].corr()\n",
    "    print(\"\\nCorrelation with target (fare_amount):\")\n",
    "    print(corr[\"fare_amount\"].sort_values(ascending=False))\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Define X and y\n",
    "X = df.drop(columns=[\"fare_amount\"])\n",
    "y = df[\"fare_amount\"]\n",
    "\n",
    "# Preprocessing pipeline\n",
    "num_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_transformer, numeric_cols),\n",
    "    (\"cat\", cat_transformer, categorical_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso\": Lasso(alpha=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    results[name] = {\"r2\": r2, \"rmse\": rmse}\n",
    "    print(f\"\\n{name} -> R2: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Show a summary table\n",
    "res_df = pd.DataFrame(results).T\n",
    "display(res_df)\n",
    "\n",
    "# Cross-validation example on Linear Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", LinearRegression())])\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=5, scoring=\"r2\")\n",
    "print(\"\\nLinearRegression CV R2 scores:\", cv_scores)\n",
    "print(\"Mean CV R2:\", cv_scores.mean())\n",
    "\n",
    "print(\"\\nDone. Replace synthetic data with your real './uber.csv' and re-run for actual results.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
